{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d0bf8a9",
      "metadata": {
        "id": "1d0bf8a9",
        "outputId": "0a747ca8-74c9-4ab9-93ee-09f15b165ba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q swig\n",
        "%pip install -q gymnasium[box2d,classic_control]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0366e4b5",
      "metadata": {
        "id": "0366e4b5"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "def run_episode(agent_function, max_steps=1000):\n",
        "    \"\"\"Run one episode in the LunarLander-v3 environment using the provided agent.\"\"\"\n",
        "\n",
        "    # Initialize the environment\n",
        "    env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
        "\n",
        "    # Reset the environment to generate the first observation (use seed=42 in reset to get reproducible results)\n",
        "    observation, info = env.reset()\n",
        "\n",
        "    # run one episode\n",
        "    for _ in range(max_steps):\n",
        "        # call the agent function to select an action\n",
        "        action = agent_function(observation)\n",
        "\n",
        "        print (f\"Obs: {observation} -> Action: {action}\")\n",
        "\n",
        "        # step: execute an action in the environment\n",
        "        observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        env.render()\n",
        "\n",
        "        if terminated:\n",
        "            print(f\"Final Reward: {reward}\")\n",
        "            break\n",
        "\n",
        "    env.close()\n",
        "    return reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "add54072",
      "metadata": {
        "id": "add54072"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "\n",
        "class Act(Enum):\n",
        "    LEFT = 1\n",
        "    RIGHT = 3\n",
        "    MAIN = 2\n",
        "    NO_OP = 0\n",
        "\n",
        "class Obs(Enum):\n",
        "    X = 0\n",
        "    Y = 1\n",
        "    VX = 2\n",
        "    VY = 3\n",
        "    ANGLE = 4\n",
        "    ANGULAR_VELOCITY = 5\n",
        "    LEFT_LEG_CONTACT = 6\n",
        "    RIGHT_LEG_CONTACT = 7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8f06b1",
      "metadata": {
        "id": "8b8f06b1",
        "outputId": "6790733f-3f66-4cc3-d8c1-ba4b762a6444"
      },
      "outputs": [],
      "source": [
        "def rocket_agent_function(observation):\n",
        "    \"\"\"A simple agent function.\"\"\"\n",
        "\n",
        "    # run the main thruster, if the lander is falling too fast\n",
        "    if observation[Obs.VY.value] < -.3:\n",
        "        return Act.MAIN.value\n",
        "\n",
        "    return Act.NO_OP.value\n",
        "\n",
        "run_episode(rocket_agent_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b4d789df",
      "metadata": {
        "id": "b4d789df",
        "outputId": "33146cda-f454-483b-f7bd-caebd04c27bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
            "Average reward: -98.0\n",
            "Success rate: 1/100\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def run_episode_test(agent_function):\n",
        "    \"\"\"Run one episode in the LunarLander-v3 environment using the provided agent.\"\"\"\n",
        "\n",
        "    # Initialise the environment\n",
        "    env = gym.make(\"LunarLander-v3\", render_mode=None)\n",
        "\n",
        "    # Reset the environment to generate the first observation\n",
        "    observation, info = env.reset()\n",
        "\n",
        "    # run one episode (max. 1000 steps)\n",
        "    for _ in range(1000):\n",
        "        # call the agent to select an action\n",
        "        action = agent_function(observation)\n",
        "\n",
        "        # step (transition) through the environment with the action\n",
        "        observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        if terminated:\n",
        "            break\n",
        "\n",
        "    env.close()\n",
        "    return reward\n",
        "\n",
        "def run_episodes(agent_function, n=100):\n",
        "    \"\"\"Run multiple episodes with the given agent and return the rewards for each episode.\"\"\"\n",
        "    return [run_episode_test(agent_function) for _ in range(n)]\n",
        "\n",
        "rewards = run_episodes(rocket_agent_function)\n",
        "print(rewards)\n",
        "\n",
        "print(f\"Average reward: {np.average(rewards)}\")\n",
        "print(f\"Success rate: {np.sum(np.array(rewards) == 100)}/{len(rewards)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2699bae2",
      "metadata": {
        "id": "2699bae2"
      },
      "source": [
        "This is not great!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d3af054",
      "metadata": {
        "id": "3d3af054"
      },
      "source": [
        "\n",
        "## Implement A Better Reflex-Based Agent\n",
        "\n",
        "Build a better that uses its right and left thrusters to land the craft (more) safely. Test your agent function using 100 problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b6f4000",
      "metadata": {
        "id": "6b6f4000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-100, 100, 100, -100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, -100, 100, 100, 100, 100, 100, 100, 100, np.float64(-0.2883425350688771), 100, -100, -100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, -100, -100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, np.float64(-0.006137363436720306), 100, 100, 100, 100, -100, 100, 100, 100, -100, 100, 100, 100, 100, 100, 100, 100, 100, 100, -100, 100, 100]\n",
            "Average reward: 77.99705520101494\n",
            "Success rate: 88/100\n"
          ]
        }
      ],
      "source": [
        "# Code goes here\n",
        "def better_agent_function(observation):\n",
        "    #calculating the target angle to balance the rocket so that it could land on target\n",
        "    target_angle = observation[Obs.X.value] * 0.5 + observation[Obs.VX.value] * 0.5\n",
        "\n",
        "    #calculating the difference between the ideal angle and the actual rocket angle\n",
        "    angle_error_correction = (target_angle - observation[Obs.ANGLE.value])\n",
        "\n",
        "    #calculating the ideal thrust\n",
        "    control_signal = angle_error_correction - observation[Obs.ANGULAR_VELOCITY.value]\n",
        "\n",
        "    action = Act.NO_OP.value\n",
        "\n",
        "    #acting based on the control_signal value\n",
        "    if control_signal > 0.15:\n",
        "        action = Act.LEFT.value\n",
        "    elif control_signal < -0.15:\n",
        "        action = Act.RIGHT.value\n",
        "\n",
        "    #Decision when rocket angle is not too extreme \n",
        "    if abs(observation[Obs.ANGLE.value]) < 0.5:\n",
        "        if observation[Obs.VY.value] < -0.1:\n",
        "            action = Act.MAIN.value\n",
        "    \n",
        "    #Decision when the left and right leg makes contact on landing surface\n",
        "    if observation[Obs.LEFT_LEG_CONTACT.value] and observation[Obs.RIGHT_LEG_CONTACT.value]:\n",
        "        action = Act.NO_OP.value\n",
        "\n",
        "    return action\n",
        "\n",
        "better_rewards = run_episodes(better_agent_function)\n",
        "print(better_rewards)\n",
        "print(f\"Average reward: {np.average(better_rewards)}\")\n",
        "print(f\"Success rate: {np.sum(np.array(better_rewards) == 100)}/{len(rewards)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fdaa8ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Fungsi yang digunakan untuk menjalankan agent pada satu skenario \n",
        "run_episode(better_agent_function)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lunar_lander",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
